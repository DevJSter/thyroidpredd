{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Preprocessed_data.csv')\n",
    "\n",
    "#Dividing target variable from the main dataset\n",
    "\n",
    "X = data.iloc[: , 0:-1]\n",
    "Y = data.iloc[: , -1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical data\n",
    "## Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_train_cat_encoded = pd.DataFrame(ordinal_encoder.fit_transform(X_train.select_dtypes(exclude='number')))\n",
    "X_train_cat_encoded.columns = X_train.select_dtypes(exclude='number').columns\n",
    "\n",
    "X_test_cat_encoded = pd.DataFrame(ordinal_encoder.transform(X_test.select_dtypes(exclude='number')))\n",
    "X_test_cat_encoded.columns = X_test.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y_train_cat_encoded= pd.DataFrame(label_encoder.fit_transform(Y_train))\n",
    "Y_test_cat_encoded = pd.DataFrame(label_encoder.transform(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc=pd.DataFrame(sc.fit_transform(X_train.select_dtypes(exclude='O')))\n",
    "X_test_sc=pd.DataFrame(sc.transform(X_test.select_dtypes(exclude='O')))\n",
    "\n",
    "X_train_sc.columns=X_train.select_dtypes(exclude='O').columns\n",
    "X_test_sc.columns=X_test.select_dtypes(exclude='O').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final=pd.concat([X_train_sc,X_train_cat_encoded],axis=1)\n",
    "X_test_final=pd.concat([X_test_sc,X_test_cat_encoded],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imbalanced Dataset\n",
    "### Since the dataset is small, will use over-sampling: SMOTE technique to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7852, 28), (1476, 28), (7852, 1), (1476, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resample,Y_train_resample=SMOTE(random_state=0,k_neighbors=1).fit_resample(X_train_final,Y_train_cat_encoded)\n",
    "X_test_resample,Y_test_resample=SMOTE(random_state=0,k_neighbors=1).fit_resample(X_test_final,Y_test_cat_encoded)\n",
    "\n",
    "X_train_resample.shape,X_test_resample.shape,Y_train_resample.shape,Y_test_resample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (7852, 28) (7852, 1)\n",
      "Testing dataset shape: (1476, 28) (1476, 1)\n",
      "Training dataset shape: (7852, 28) (7852,)\n",
      "Testing dataset shape: (1476, 28) (1476,)\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset shape:', X_train_resample.shape, Y_train_resample.shape)\n",
    "print('Testing dataset shape:', X_test_resample.shape, Y_test_resample.shape)\n",
    "\n",
    "Y_train_resample_flat = Y_train_resample.to_numpy().ravel()\n",
    "Y_test_resample_flat = Y_test_resample.to_numpy().ravel()\n",
    "\n",
    "print('Training dataset shape:', X_train_resample.shape, Y_train_resample_flat.shape)\n",
    "print('Testing dataset shape:', X_test_resample.shape, Y_test_resample_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward selection approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   37.5s finished\n",
      "\n",
      "[2024-01-27 07:11:55] Features: 1/10 -- score: 0.7903703673671278[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   49.4s finished\n",
      "\n",
      "[2024-01-27 07:12:45] Features: 2/10 -- score: 0.9689245764189307[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:   49.3s finished\n",
      "\n",
      "[2024-01-27 07:13:34] Features: 3/10 -- score: 0.987647204304127[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  1.1min finished\n",
      "\n",
      "[2024-01-27 07:14:43] Features: 4/10 -- score: 0.9950328201843119[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  1.1min finished\n",
      "\n",
      "[2024-01-27 07:15:50] Features: 5/10 -- score: 0.9978347192546433[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:   48.6s finished\n",
      "\n",
      "[2024-01-27 07:16:39] Features: 6/10 -- score: 0.9980894963247071[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:   44.5s finished\n",
      "\n",
      "[2024-01-27 07:17:23] Features: 7/10 -- score: 0.998089577412253[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:   40.6s finished\n",
      "\n",
      "[2024-01-27 07:18:04] Features: 8/10 -- score: 0.9982168848597388[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:   51.5s finished\n",
      "\n",
      "[2024-01-27 07:18:56] Features: 9/10 -- score: 0.9979621888772211[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:   42.6s finished\n",
      "\n",
      "[2024-01-27 07:19:38] Features: 10/10 -- score: 0.9980894963247069"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "forward_fs = sfs(rf , k_features=10,forward=True,floating=False,verbose=2,scoring='accuracy',cv=5)\n",
    "forward_fs = forward_fs.fit(X_train_resample, Y_train_resample_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Handler for logging records/messages to a file\n",
    "file_handler = logging.FileHandler(\"log_file.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the format of the log records and the logging level to DEBUG\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function  to create and save logs in the log files\n",
    "def log(path, file):\n",
    "    \"\"\"[Create a log file to record the experiment's logs]\n",
    "    \n",
    "    Arguments:\n",
    "        path {string} -- path to the directory\n",
    "        file {string} -- file name\n",
    "    \n",
    "    Returns:\n",
    "        [obj] -- [logger that record logs]\n",
    "    \"\"\"\n",
    "\n",
    "    # check if the file exist\n",
    "    log_file = os.path.join(path, file)\n",
    "\n",
    "    if not os.path.isfile(log_file):\n",
    "        open(log_file, \"w+\").close()\n",
    "\n",
    "    console_logging_format = \"%(levelname)s %(message)s\"\n",
    "    file_logging_format = \"%(levelname)s: %(asctime)s: %(message)s\"\n",
    "\n",
    "    # configure logger\n",
    "    logging.basicConfig(level=logging.INFO, format=console_logging_format)\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    # create a file handler for output file\n",
    "    handler = logging.FileHandler(log_file)\n",
    "\n",
    "    # set the logging level for log file\n",
    "    handler.setLevel(logging.INFO)\n",
    "    \n",
    "    # create a logging format\n",
    "    formatter = logging.Formatter(file_logging_format)\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    # add the handlers to the logger\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/log_file.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m logger \u001b[38;5;241m=\u001b[39m \u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_file.log\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m, in \u001b[0;36mlog\u001b[1;34m(path, file)\u001b[0m\n\u001b[0;32m     14\u001b[0m log_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, file)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(log_file):\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m     19\u001b[0m console_logging_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m file_logging_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%(levelname)s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%(asctime)s\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%(message)s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/log_file.log'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "logger = log(path=\"/\",file=\"log_file.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Feature Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logger' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m feat_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(forward_fs\u001b[38;5;241m.\u001b[39mk_feature_names_)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mlogger\u001b[49m\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeatures \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(feat_names))\n\u001b[0;32m      3\u001b[0m X_train_new\u001b[38;5;241m=\u001b[39mX_train_resample[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTT4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFTI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_thyroxine\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_antithyroid_medication\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoitre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhypopituitary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsych\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT3_measured\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      4\u001b[0m X_test_new\u001b[38;5;241m=\u001b[39mX_test_resample[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTSH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTT4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFTI\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_thyroxine\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_antithyroid_medication\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoitre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhypopituitary\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsych\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT3_measured\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logger' is not defined"
     ]
    }
   ],
   "source": [
    "feat_names = list(forward_fs.k_feature_names_)\n",
    "logger.info(\"Features {}\".format(feat_names))\n",
    "X_train_new=X_train_resample[['age','sex','TSH', 'TT4', 'FTI', 'on_thyroxine', 'on_antithyroid_medication', 'goitre', 'hypopituitary', 'psych', 'T3_measured']]\n",
    "X_test_new=X_test_resample[['age','sex','TSH', 'TT4', 'FTI', 'on_thyroxine', 'on_antithyroid_medication', 'goitre', 'hypopituitary', 'psych', 'T3_measured']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the Random Forest model\n",
    "rf_model=rf.fit(X_train_new,Y_train_resample_flat)\n",
    "\n",
    "logger.info(\"Traininig Random Forest Model\")\n",
    "\n",
    "#Checking the metrics of Random Forest\n",
    "def print_Score(clf,x_train,x_test,y_train,y_test,train=True):\n",
    "    if train:\n",
    "        pred=clf.predict(x_train)\n",
    "        clf_report=pd.DataFrame(classification_report(y_train,pred,output_dict=True))\n",
    "        print(\"Train Result:\\n===============\")\n",
    "        print(f\"Accuracy Score:{accuracy_score(y_train,pred)*100:.2f}%\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(f\"Classification Report:\\n{clf_report}\")\n",
    "        print(\"-----------------------------------\")\n",
    "        print(f\"Confusion Matrix:\\n{confusion_matrix(y_train,pred)}\\n\")\n",
    "        logger.info(\"Train Result:\\n===============\"+\"\\n\"+\n",
    "                    f\"Accuracy Score:{accuracy_score(y_train,pred)*100:.2f}%\"\"\\n\"+\n",
    "        \"---------------------------------\"+\"\\n\"+\n",
    "        f\"Classification Report:\\n{clf_report}\"+\"\\n\"+\n",
    "        \"-----------------------------------\"+\"\\n\"+\n",
    "        f\"Confusion Matrix:\\n{confusion_matrix(y_train,pred)}\\n\")\n",
    "    elif train==False:\n",
    "        pred=clf.predict(x_test)\n",
    "        clf_report=pd.DataFrame(classification_report(y_test,pred,output_dict=True))\n",
    "        print(\"Test Result:\\n===============\")\n",
    "        print(f\"Accuracy Score:{accuracy_score(y_test,pred)*100:.2f}%\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(f\"Classification Report:\\n{clf_report}\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(f\"Confusion Matrix:\\n{confusion_matrix(y_test,pred)}\\n\")\n",
    "        \n",
    "        logger.info(\"Test Result:\\n===============\"+\"\\n\"+\n",
    "        f\"Accuracy Score:{accuracy_score(y_test,pred)*100:.2f}%\"+\"\\n\"+\n",
    "        \"---------------------------------\"+\"\\n\"+\n",
    "        f\"Classification Report:\\n{clf_report}\"+\"\\n\"+\n",
    "        \"---------------------------------\"+\"\\n\"+\n",
    "        f\"Confusion Matrix:\\n{confusion_matrix(y_test,pred)}\\n\")\n",
    "        \n",
    "print_Score(rf_model,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=True)\n",
    "print_Score(rf_model,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyper parameter tuning\n",
    "RF=RandomForestClassifier()\n",
    "model=RF.fit(X_train_new,Y_train_resample_flat)\n",
    "\n",
    "print_Score(model,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=True)\n",
    "print_Score(model,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomized Search CV\n",
    "\n",
    "#No of trees in Random Forest\n",
    "n_estimators=[int(x) for x in np.linspace(start=200,stop=2000,num=10)]\n",
    "#No of features consider at every split\n",
    "max_features=['auto','sqrt','log2']\n",
    "#maximum no of levels in trees\n",
    "max_depth=[int(x) for x in np.linspace(10,1000,10)]\n",
    "#minimum no of samples required to split a node\n",
    "min_samples_split=[1,3,4,5,7,9]\n",
    "#minimum samples leafs required at each leaf node\n",
    "min_sample_leafs=[1,2,4,6,8]\n",
    "\n",
    "#create random gird\n",
    "random_grid={'n_estimators':n_estimators,\n",
    "'max_features':max_features,\n",
    "'max_depth':max_depth,\n",
    "'min_samples_split':min_samples_split,\n",
    "'min_samples_leaf':min_sample_leafs,\n",
    "'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv=RandomizedSearchCV(estimator=RF,param_distributions=random_grid,n_iter=100,cv=3,verbose=2,random_state=0,n_jobs=-1)\n",
    "\n",
    "rcv.fit(X_train_new,Y_train_resample_flat)\n",
    "\n",
    "logger.info(\"Use Randomized Search CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv.best_estimator_\n",
    "logger.info(rcv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_grid=rcv.best_estimator_\n",
    "logger.info(\"Result with best estimetors\")\n",
    "print_Score(best_random_grid,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': [rcv.best_params_['criterion']],\n",
    "    'max_depth': [rcv.best_params_['max_depth']],\n",
    "    'max_features': [rcv.best_params_['max_features']],\n",
    "    'min_samples_leaf': [rcv.best_params_['min_samples_leaf'], \n",
    "                         rcv.best_params_['min_samples_leaf']+2, \n",
    "                         rcv.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split': [rcv.best_params_['min_samples_split'] - 2,\n",
    "                          rcv.best_params_['min_samples_split'] - 1,\n",
    "                          rcv.best_params_['min_samples_split'], \n",
    "                          rcv.best_params_['min_samples_split'] +1,\n",
    "                          rcv.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [rcv.best_params_['n_estimators'] - 200, rcv.best_params_['n_estimators'] - 100, \n",
    "                     rcv.best_params_['n_estimators'], \n",
    "                     rcv.best_params_['n_estimators'] + 100, rcv.best_params_['n_estimators'] + 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param_grid)\n",
    "logger.info(f\"Parameter Grid: {param_grid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(estimator=RF,param_grid=param_grid,cv=10,n_jobs=1,verbose=2)\n",
    "grid_search.fit(X_train_new,Y_train_resample_flat)\n",
    "logger.info(\"Grid Search CV: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid=grid_search.best_estimator_\n",
    "best_grid\n",
    "logger.info(f\"Best Grid: {best_grid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Result with Best Grid: \")\n",
    "print_Score(best_grid,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, will convert our final model into pickle file\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out=open('Thyroid_model.pkl','wb')\n",
    "pickle.dump(grid_search,pickle_out)\n",
    "pickle_out.close()\n",
    "logger.info(\"Random Forest Model with Grid Search Saved in Pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
