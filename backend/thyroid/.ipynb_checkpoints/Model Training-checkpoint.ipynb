{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import pandas as pd\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Preprocessed_data.csv')\n",
    "\n",
    "#Dividing target variable from the main dataset\n",
    "\n",
    "X = data.iloc[: , 0:-1]\n",
    "Y = data.iloc[: , -1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding categorical data\n",
    "## Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder = OrdinalEncoder()\n",
    "X_train_cat_encoded = pd.DataFrame(ordinal_encoder.fit_transform(X_train.select_dtypes(exclude='number')))\n",
    "X_train_cat_encoded.columns = X_train.select_dtypes(exclude='number').columns\n",
    "\n",
    "X_test_cat_encoded = pd.DataFrame(ordinal_encoder.transform(X_test.select_dtypes(exclude='number')))\n",
    "X_test_cat_encoded.columns = X_test.select_dtypes(exclude='number').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "Y_train_cat_encoded= pd.DataFrame(label_encoder.fit_transform(Y_train))\n",
    "Y_test_cat_encoded = pd.DataFrame(label_encoder.transform(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_sc=pd.DataFrame(sc.fit_transform(X_train.select_dtypes(exclude='O')))\n",
    "X_test_sc=pd.DataFrame(sc.transform(X_test.select_dtypes(exclude='O')))\n",
    "\n",
    "X_train_sc.columns=X_train.select_dtypes(exclude='O').columns\n",
    "X_test_sc.columns=X_test.select_dtypes(exclude='O').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final=pd.concat([X_train_sc,X_train_cat_encoded],axis=1)\n",
    "X_test_final=pd.concat([X_test_sc,X_test_cat_encoded],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling imbalanced Dataset\n",
    "### Since the dataset is small, will use over-sampling: SMOTE technique to balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7852, 28), (1476, 28), (7852, 1), (1476, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_resample,Y_train_resample=SMOTE(random_state=0,k_neighbors=1).fit_resample(X_train_final,Y_train_cat_encoded)\n",
    "X_test_resample,Y_test_resample=SMOTE(random_state=0,k_neighbors=1).fit_resample(X_test_final,Y_test_cat_encoded)\n",
    "\n",
    "X_train_resample.shape,X_test_resample.shape,Y_train_resample.shape,Y_test_resample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (7852, 28) (7852, 1)\n",
      "Testing dataset shape: (1476, 28) (1476, 1)\n",
      "Training dataset shape: (7852, 28) (7852,)\n",
      "Testing dataset shape: (1476, 28) (1476,)\n"
     ]
    }
   ],
   "source": [
    "print('Training dataset shape:', X_train_resample.shape, Y_train_resample.shape)\n",
    "print('Testing dataset shape:', X_test_resample.shape, Y_test_resample.shape)\n",
    "\n",
    "Y_train_resample_flat = Y_train_resample.to_numpy().ravel()\n",
    "Y_test_resample_flat = Y_test_resample.to_numpy().ravel()\n",
    "\n",
    "print('Training dataset shape:', X_train_resample.shape, Y_train_resample_flat.shape)\n",
    "print('Testing dataset shape:', X_test_resample.shape, Y_test_resample_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward selection approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:   37.5s finished\n",
      "\n",
      "[2024-01-27 07:11:55] Features: 1/10 -- score: 0.7903703673671278[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   49.4s finished\n",
      "\n",
      "[2024-01-27 07:12:45] Features: 2/10 -- score: 0.9689245764189307[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.9s remaining:    0.0s\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "forward_fs = sfs(rf , k_features=10,forward=True,floating=False,verbose=2,scoring='accuracy',cv=5)\n",
    "forward_fs = forward_fs.fit(X_train_resample, Y_train_resample_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Handler for logging records/messages to a file\n",
    "file_handler = logging.FileHandler(\"log_file.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the format of the log records and the logging level to DEBUG\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function  to create and save logs in the log files\n",
    "def log(path, file):\n",
    "    \"\"\"[Create a log file to record the experiment's logs]\n",
    "    \n",
    "    Arguments:\n",
    "        path {string} -- path to the directory\n",
    "        file {string} -- file name\n",
    "    \n",
    "    Returns:\n",
    "        [obj] -- [logger that record logs]\n",
    "    \"\"\"\n",
    "\n",
    "    # check if the file exist\n",
    "    log_file = os.path.join(path, file)\n",
    "\n",
    "    if not os.path.isfile(log_file):\n",
    "        open(log_file, \"w+\").close()\n",
    "\n",
    "    console_logging_format = \"%(levelname)s %(message)s\"\n",
    "    file_logging_format = \"%(levelname)s: %(asctime)s: %(message)s\"\n",
    "\n",
    "    # configure logger\n",
    "    logging.basicConfig(level=logging.INFO, format=console_logging_format)\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    # create a file handler for output file\n",
    "    handler = logging.FileHandler(log_file)\n",
    "\n",
    "    # set the logging level for log file\n",
    "    handler.setLevel(logging.INFO)\n",
    "    \n",
    "    # create a logging format\n",
    "    formatter = logging.Formatter(file_logging_format)\n",
    "    handler.setFormatter(formatter)\n",
    "\n",
    "    # add the handlers to the logger\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = log(path=\".\",file=\"log_file.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Feature Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = list(forward_fs.k_feature_names_)\n",
    "logger.info(\"Features {}\".format(feat_names))\n",
    "X_train_new=X_train_resample[['age','sex','TSH', 'TT4', 'FTI', 'on_thyroxine', 'on_antithyroid_medication', 'goitre', 'hypopituitary', 'psych', 'T3_measured']]\n",
    "X_test_new=X_test_resample[['age','sex','TSH', 'TT4', 'FTI', 'on_thyroxine', 'on_antithyroid_medication', 'goitre', 'hypopituitary', 'psych', 'T3_measured']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the Random Forest model\n",
    "rf_model=rf.fit(X_train_new,Y_train_resample_flat)\n",
    "\n",
    "logger.info(\"Traininig Random Forest Model\")\n",
    "\n",
    "#Checking the metrics of Random Forest\n",
    "def print_Score(clf,x_train,x_test,y_train,y_test,train=True):\n",
    "    if train:\n",
    "        pred=clf.predict(x_train)\n",
    "        clf_report=pd.DataFrame(classification_report(y_train,pred,output_dict=True))\n",
    "        print(\"Train Result:\\n===============\")\n",
    "        print(f\"Accuracy Score:{accuracy_score(y_train,pred)*100:.2f}%\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(f\"Classification Report:\\n{clf_report}\")\n",
    "        print(\"-----------------------------------\")\n",
    "        print(f\"Confusion Matrix:\\n{confusion_matrix(y_train,pred)}\\n\")\n",
    "        logger.info(\"Train Result:\\n===============\"+\"\\n\"+\n",
    "                    f\"Accuracy Score:{accuracy_score(y_train,pred)*100:.2f}%\"\"\\n\"+\n",
    "        \"---------------------------------\"+\"\\n\"+\n",
    "        f\"Classification Report:\\n{clf_report}\"+\"\\n\"+\n",
    "        \"-----------------------------------\"+\"\\n\"+\n",
    "        f\"Confusion Matrix:\\n{confusion_matrix(y_train,pred)}\\n\")\n",
    "    elif train==False:\n",
    "        pred=clf.predict(x_test)\n",
    "        clf_report=pd.DataFrame(classification_report(y_test,pred,output_dict=True))\n",
    "        print(\"Test Result:\\n===============\")\n",
    "        print(f\"Accuracy Score:{accuracy_score(y_test,pred)*100:.2f}%\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(f\"Classification Report:\\n{clf_report}\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(f\"Confusion Matrix:\\n{confusion_matrix(y_test,pred)}\\n\")\n",
    "        \n",
    "        logger.info(\"Test Result:\\n===============\"+\"\\n\"+\n",
    "        f\"Accuracy Score:{accuracy_score(y_test,pred)*100:.2f}%\"+\"\\n\"+\n",
    "        \"---------------------------------\"+\"\\n\"+\n",
    "        f\"Classification Report:\\n{clf_report}\"+\"\\n\"+\n",
    "        \"---------------------------------\"+\"\\n\"+\n",
    "        f\"Confusion Matrix:\\n{confusion_matrix(y_test,pred)}\\n\")\n",
    "        \n",
    "print_Score(rf_model,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=True)\n",
    "print_Score(rf_model,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Hyper parameter tuning\n",
    "RF=RandomForestClassifier()\n",
    "model=RF.fit(X_train_new,Y_train_resample_flat)\n",
    "\n",
    "print_Score(model,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=True)\n",
    "print_Score(model,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomized Search CV\n",
    "\n",
    "#No of trees in Random Forest\n",
    "n_estimators=[int(x) for x in np.linspace(start=200,stop=2000,num=10)]\n",
    "#No of features consider at every split\n",
    "max_features=['auto','sqrt','log2']\n",
    "#maximum no of levels in trees\n",
    "max_depth=[int(x) for x in np.linspace(10,1000,10)]\n",
    "#minimum no of samples required to split a node\n",
    "min_samples_split=[1,3,4,5,7,9]\n",
    "#minimum samples leafs required at each leaf node\n",
    "min_sample_leafs=[1,2,4,6,8]\n",
    "\n",
    "#create random gird\n",
    "random_grid={'n_estimators':n_estimators,\n",
    "'max_features':max_features,\n",
    "'max_depth':max_depth,\n",
    "'min_samples_split':min_samples_split,\n",
    "'min_samples_leaf':min_sample_leafs,\n",
    "'criterion':['entropy','gini']}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv=RandomizedSearchCV(estimator=RF,param_distributions=random_grid,n_iter=100,cv=3,verbose=2,random_state=0,n_jobs=-1)\n",
    "\n",
    "rcv.fit(X_train_new,Y_train_resample_flat)\n",
    "\n",
    "logger.info(\"Use Randomized Search CV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv.best_estimator_\n",
    "logger.info(rcv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random_grid=rcv.best_estimator_\n",
    "logger.info(\"Result with best estimetors\")\n",
    "print_Score(best_random_grid,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': [rcv.best_params_['criterion']],\n",
    "    'max_depth': [rcv.best_params_['max_depth']],\n",
    "    'max_features': [rcv.best_params_['max_features']],\n",
    "    'min_samples_leaf': [rcv.best_params_['min_samples_leaf'], \n",
    "                         rcv.best_params_['min_samples_leaf']+2, \n",
    "                         rcv.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split': [rcv.best_params_['min_samples_split'] - 2,\n",
    "                          rcv.best_params_['min_samples_split'] - 1,\n",
    "                          rcv.best_params_['min_samples_split'], \n",
    "                          rcv.best_params_['min_samples_split'] +1,\n",
    "                          rcv.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [rcv.best_params_['n_estimators'] - 200, rcv.best_params_['n_estimators'] - 100, \n",
    "                     rcv.best_params_['n_estimators'], \n",
    "                     rcv.best_params_['n_estimators'] + 100, rcv.best_params_['n_estimators'] + 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(param_grid)\n",
    "logger.info(f\"Parameter Grid: {param_grid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV(estimator=RF,param_grid=param_grid,cv=10,n_jobs=1,verbose=2)\n",
    "grid_search.fit(X_train_new,Y_train_resample_flat)\n",
    "logger.info(\"Grid Search CV: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid=grid_search.best_estimator_\n",
    "best_grid\n",
    "logger.info(f\"Best Grid: {best_grid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Result with Best Grid: \")\n",
    "print_Score(best_grid,X_train_new,X_test_new,Y_train_resample_flat,Y_test_resample_flat,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, will convert our final model into pickle file\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_out=open('Thyroid_model.pkl','wb')\n",
    "pickle.dump(grid_search,pickle_out)\n",
    "pickle_out.close()\n",
    "logger.info(\"Random Forest Model with Grid Search Saved in Pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
